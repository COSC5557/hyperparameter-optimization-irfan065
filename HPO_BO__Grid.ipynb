{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "xJt79MtsDqhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy import stats\n",
        "import warnings\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.exceptions import FitFailedWarning\n"
      ],
      "metadata": {
        "id": "ugGZ9-tzD38v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data"
      ],
      "metadata": {
        "id": "Tw75-XBnEQo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('wineq.csv')\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "fePeR-8UEckD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm Selection"
      ],
      "metadata": {
        "id": "DsUhKw34FPEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models = [\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('SVM', SVC()),\n",
        "    ('Logistic Regression', LogisticRegression()),\n",
        "    ('Decision Tree', DecisionTreeClassifier())\n",
        "]\n"
      ],
      "metadata": {
        "id": "0Y70ACnlFZll"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-Validation and Model Evaluation"
      ],
      "metadata": {
        "id": "kqiJUMShFhXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "results = {}\n",
        "for name, model in models:\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    results[name] = scores"
      ],
      "metadata": {
        "id": "saRL5EJBFmzN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Selection"
      ],
      "metadata": {
        "id": "hbjtuoytHXP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_scores = {}\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    final_scores[name] = accuracy\n",
        "\n",
        "best_model = max(final_scores, key=final_scores.get)\n",
        "for name, accuracy in final_scores.items():\n",
        "    print(f\"{name} Accuracy: {accuracy}\")\n",
        "print(\"Best Model:\", best_model, final_scores[best_model])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuMrvU8cHWaR",
        "outputId": "f81140d5-257e-4b1d-b25e-18056fb1eee4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.71875\n",
            "SVM Accuracy: 0.503125\n",
            "Logistic Regression Accuracy: 0.63125\n",
            "Decision Tree Accuracy: 0.678125\n",
            "Best Model: Random Forest 0.71875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "K0ACs4G1RuP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
        "\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=100),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'Logistic Regression': {'C': [0.1, 0.5, 1, 5, 10], 'penalty': ['l1', 'l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
        "    'Decision Tree': {'max_depth': [None, 10, 20, 30, 50, 100], 'min_samples_split': [2, 5, 10, 15], 'min_samples_leaf': [1, 2, 4, 7]},\n",
        "    'Random Forest': {'n_estimators': [10, 50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
        "    'SVM': {'C': [0.1, 0.8, 2, 10], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
        "}\n",
        "\n",
        "\n",
        "for clf_name, clf in classifiers.items():\n",
        "    param_grid = param_grids[clf_name]\n",
        "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    cv_scores = cross_val_score(grid_search, X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
        "\n",
        "    best_model = grid_search.fit(X_train, y_train).best_estimator_\n",
        "    test_accuracy = best_model.score(X_test, y_test)\n",
        "\n",
        "    print(f\"Nested Cross-Validation Results for {clf_name}:\")\n",
        "    print(\"Best Hyperparameters:\", best_model.get_params())\n",
        "    print(\"Cross-Validation Accuracy: {:.4f} (+/- {:.4f})\".format(cv_scores.mean(), cv_scores.std() * 2))\n",
        "    print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "    print(\"\\n\")\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
        "\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=100),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC()\n",
        "}\n",
        "\n",
        "\n",
        "param_grids = {\n",
        "    'Logistic Regression': {'C': [0.1, 0.5, 1, 5, 10], 'penalty': ['l1', 'l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
        "    'Decision Tree': {'max_depth': [None, 10, 20, 30, 50, 100], 'min_samples_split': [2, 5, 10, 15], 'min_samples_leaf': [1, 2, 4, 7]},\n",
        "    'Random Forest': {'n_estimators': [10, 50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
        "    'SVM': {'C': [0.1, 0.8, 2, 10], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
        "}\n",
        "\n",
        "# Perform nested resampling\n",
        "for clf_name, clf in classifiers.items():\n",
        "    param_grid = param_grids[clf_name]\n",
        "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    cv_scores = cross_val_score(grid_search, X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
        "\n",
        "    best_model = grid_search.fit(X_train, y_train).best_estimator_\n",
        "    test_accuracy = best_model.score(X_test, y_test)\n",
        "\n",
        "    print(f\"Nested Cross-Validation Results for {clf_name}:\")\n",
        "    print(\"Best Hyperparameters:\", best_model.get_params())\n",
        "    print(\"Cross-Validation Accuracy: {:.4f} (+/- {:.4f})\".format(cv_scores.mean(), cv_scores.std() * 2))\n",
        "    print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYf5t-y6FATs",
        "outputId": "31052f6c-3dc1-4166-bc10-6bd051c5edb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5366858         nan 0.49170732 0.57576279\n",
            " 0.56207556 0.55133429 0.50246294 0.49072692        nan        nan\n",
            " 0.56697274        nan 0.48975132 0.58458632 0.5660067  0.56501196\n",
            " 0.50148254 0.49072692        nan        nan 0.57186035        nan\n",
            " 0.48975132 0.58165471 0.567934   0.57089909 0.50148254 0.48975132\n",
            "        nan        nan 0.56795791        nan 0.48975132 0.57971784\n",
            " 0.56988522 0.57186035 0.50148254 0.48975132        nan        nan\n",
            " 0.56795313        nan 0.48877092 0.57384983 0.56597322 0.56990913\n",
            " 0.50148254 0.48877092]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.522989          nan 0.50832138 0.58655667\n",
            " 0.56992348 0.55233381 0.51221425 0.5102726         nan        nan\n",
            " 0.56113821        nan 0.5092922  0.58656624 0.57675275 0.56308465\n",
            " 0.51221903 0.5092922         nan        nan 0.57286944        nan\n",
            " 0.5102726  0.58754663 0.57775227 0.56993783 0.51221903 0.5102726\n",
            "        nan        nan 0.58164515        nan 0.5102726  0.59634625\n",
            " 0.57480631 0.5826351  0.51221903 0.5102726         nan        nan\n",
            " 0.58263032        nan 0.5102726  0.59536585 0.5748111  0.58555237\n",
            " 0.51221903 0.5092922 ]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.53373505        nan 0.49659015 0.56892874\n",
            " 0.55428503 0.54646102 0.50341942 0.50341463        nan        nan\n",
            " 0.56209947        nan 0.50243902 0.57872788 0.56896222 0.5660067\n",
            " 0.50341942 0.50439503        nan        nan 0.56895744        nan\n",
            " 0.50341463 0.58263032 0.56307508 0.56601148 0.50341942 0.50439503\n",
            "        nan        nan 0.57382592        nan 0.50439503 0.58751315\n",
            " 0.56111908 0.57870875 0.50439503 0.50439503        nan        nan\n",
            " 0.57675753        nan 0.50439503 0.58654232 0.56013869 0.57869919\n",
            " 0.50341942 0.50439503]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.52784792        nan 0.49659493 0.57870397\n",
            " 0.56500239 0.54155428 0.50245337 0.49462936        nan        nan\n",
            " 0.56209469        nan 0.49658537 0.58065997 0.57574366 0.56794357\n",
            " 0.50342898 0.49462936        nan        nan 0.57284075        nan\n",
            " 0.49462936 0.58556193 0.57967001 0.5718747  0.50342898 0.49462936\n",
            "        nan        nan 0.58065041        nan 0.49462936 0.58652798\n",
            " 0.5728264  0.58065041 0.50440459 0.49462936        nan        nan\n",
            " 0.58065041        nan 0.49462936 0.59043998 0.57966523 0.5816308\n",
            " 0.50440459 0.49462936]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.52344811        nan 0.5136681  0.5791296\n",
            " 0.56252511 0.54296031 0.52049259 0.51172645        nan        nan\n",
            " 0.56056432        nan 0.50976566 0.5849737  0.56446676 0.56640363\n",
            " 0.51854137 0.51270206        nan        nan 0.56835485        nan\n",
            " 0.50976566 0.5898374  0.56251076 0.5693209  0.51854137 0.51270206\n",
            "        nan        nan 0.58494978        nan 0.51172166 0.58395983\n",
            " 0.56251076 0.57908656 0.51854615 0.51270206        nan        nan\n",
            " 0.58397896        nan 0.51270206 0.584945   0.56350072 0.58104256\n",
            " 0.51854615 0.51270206]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.53793199        nan 0.50273284 0.58327206\n",
            " 0.56529412 0.54887868 0.50977941 0.50664522        nan        nan\n",
            " 0.55512561        nan 0.50664522 0.58640012 0.57153493 0.56528186\n",
            " 0.5105576  0.50586397        nan        nan 0.57701593        nan\n",
            " 0.50742647 0.58561581 0.5676348  0.56997549 0.51133885 0.50586397\n",
            "        nan        nan 0.57309436        nan 0.50586397 0.58170956\n",
            " 0.57701593 0.57387561 0.5105576  0.50586397        nan        nan\n",
            " 0.57465993        nan 0.50586397 0.5817065  0.57154412 0.57700061\n",
            " 0.51133885 0.50586397]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation Results for Logistic Regression:\n",
            "Best Hyperparameters: {'C': 0.5, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
            "Cross-Validation Accuracy: 0.5833 (+/- 0.0254)\n",
            "Test Accuracy: 0.6250\n",
            "\n",
            "\n",
            "Nested Cross-Validation Results for Decision Tree:\n",
            "Best Hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
            "Cross-Validation Accuracy: 0.5786 (+/- 0.0500)\n",
            "Test Accuracy: 0.6500\n",
            "\n",
            "\n",
            "Nested Cross-Validation Results for Random Forest:\n",
            "Best Hyperparameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
            "Cross-Validation Accuracy: 0.6450 (+/- 0.0455)\n",
            "Test Accuracy: 0.7312\n",
            "\n",
            "\n",
            "Nested Cross-Validation Results for SVM:\n",
            "Best Hyperparameters: {'C': 0.8, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
            "Cross-Validation Accuracy: 0.5770 (+/- 0.0348)\n",
            "Test Accuracy: 0.6375\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5366858         nan 0.49170732 0.57576279\n",
            " 0.56207556 0.55133429 0.50148254 0.49072692        nan        nan\n",
            " 0.56697274        nan 0.48975132 0.58458632 0.5660067  0.56501196\n",
            " 0.50148254 0.49072692        nan        nan 0.57088474        nan\n",
            " 0.48975132 0.58165471 0.567934   0.57089909 0.50148254 0.48975132\n",
            "        nan        nan 0.56697752        nan 0.48975132 0.57971784\n",
            " 0.56988522 0.57186035 0.50148254 0.48975132        nan        nan\n",
            " 0.56697752        nan 0.48877092 0.57384983 0.56597322 0.56990913\n",
            " 0.50148254 0.48975132]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.522989          nan 0.50930177 0.58655667\n",
            " 0.56992348 0.55233381 0.51221425 0.5102726         nan        nan\n",
            " 0.56113821        nan 0.5102726  0.58656624 0.57675275 0.56308465\n",
            " 0.51221903 0.5102726         nan        nan 0.57384983        nan\n",
            " 0.5092922  0.58754663 0.57775227 0.56993783 0.51221903 0.5102726\n",
            "        nan        nan 0.58164515        nan 0.5102726  0.59634625\n",
            " 0.57480631 0.5826351  0.51221903 0.5102726         nan        nan\n",
            " 0.58263032        nan 0.5102726  0.59536585 0.5748111  0.58555237\n",
            " 0.51221903 0.51124821]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.53275945        nan 0.49659015 0.56892874\n",
            " 0.55428503 0.54646102 0.50341942 0.50341463        nan        nan\n",
            " 0.56209947        nan 0.50243902 0.57872788 0.56896222 0.5660067\n",
            " 0.50341942 0.50439503        nan        nan 0.56993783        nan\n",
            " 0.50341463 0.58263032 0.56307508 0.56601148 0.50341942 0.50439503\n",
            "        nan        nan 0.57382592        nan 0.50439503 0.58751315\n",
            " 0.56111908 0.57870875 0.50439503 0.50439503        nan        nan\n",
            " 0.57577714        nan 0.50439503 0.58654232 0.56013869 0.57869919\n",
            " 0.50341942 0.50439503]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.52784792        nan 0.49659493 0.57870397\n",
            " 0.56500239 0.54155428 0.50147776 0.49462936        nan        nan\n",
            " 0.56209469        nan 0.49658537 0.58065997 0.57574366 0.56794357\n",
            " 0.50342898 0.49462936        nan        nan 0.57284075        nan\n",
            " 0.49462936 0.58556193 0.57967001 0.5718747  0.50440459 0.49462936\n",
            "        nan        nan 0.5796748         nan 0.49462936 0.58652798\n",
            " 0.5728264  0.58065041 0.50342898 0.49462936        nan        nan\n",
            " 0.58065041        nan 0.49462936 0.59043998 0.57966523 0.5816308\n",
            " 0.50440459 0.49462936]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.52344811        nan 0.51464371 0.5791296\n",
            " 0.56252511 0.54296031 0.52049259 0.51074605        nan        nan\n",
            " 0.55958871        nan 0.50976566 0.5849737  0.56446676 0.56640363\n",
            " 0.51854137 0.51270206        nan        nan 0.56737924        nan\n",
            " 0.50976566 0.5898374  0.56251076 0.5693209  0.51854137 0.51270206\n",
            "        nan        nan 0.58494978        nan 0.51270206 0.58395983\n",
            " 0.56251076 0.57908656 0.51952176 0.51270206        nan        nan\n",
            " 0.58397896        nan 0.51270206 0.584945   0.56350072 0.58104256\n",
            " 0.51854615 0.51270206]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "75 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.53793199        nan 0.50273284 0.58327206\n",
            " 0.56529412 0.54887868 0.50977941 0.50664522        nan        nan\n",
            " 0.55590686        nan 0.50664522 0.58640012 0.57153493 0.56528186\n",
            " 0.5105576  0.50586397        nan        nan 0.57701287        nan\n",
            " 0.50742647 0.58561581 0.5676348  0.56997549 0.51133885 0.50586397\n",
            "        nan        nan 0.57153186        nan 0.50586397 0.58170956\n",
            " 0.57701593 0.57387561 0.51133885 0.50586397        nan        nan\n",
            " 0.57465993        nan 0.50586397 0.5817065  0.57154412 0.57700061\n",
            " 0.5105576  0.50586397]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation Results for Logistic Regression:\n",
            "Best Hyperparameters: {'C': 0.5, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
            "Cross-Validation Accuracy: 0.5833 (+/- 0.0254)\n",
            "Test Accuracy: 0.6250\n",
            "\n",
            "\n",
            "Nested Cross-Validation Results for Decision Tree:\n",
            "Best Hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 30, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
            "Cross-Validation Accuracy: 0.5715 (+/- 0.0085)\n",
            "Test Accuracy: 0.6625\n",
            "\n",
            "\n",
            "Nested Cross-Validation Results for Random Forest:\n",
            "Best Hyperparameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 30, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
            "Cross-Validation Accuracy: 0.6575 (+/- 0.0409)\n",
            "Test Accuracy: 0.7156\n",
            "\n",
            "\n",
            "Nested Cross-Validation Results for SVM:\n",
            "Best Hyperparameters: {'C': 0.8, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
            "Cross-Validation Accuracy: 0.5770 (+/- 0.0348)\n",
            "Test Accuracy: 0.6375\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Selection after GridSeach\n",
        "\n"
      ],
      "metadata": {
        "id": "kvAwMm8ZSBOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "final_scores = {\n",
        "    'Random Forest': rf_accuracy,\n",
        "    'SVM': svm_accuracy,\n",
        "    'Logistic Regression': logreg_accuracy,\n",
        "    'Decision Tree': dt_accuracy\n",
        "}\n",
        "\n",
        "best_model = max(final_scores, key=final_scores.get)\n",
        "\n",
        "for name, accuracy in final_scores.items():\n",
        "    print(f\"{name} Accuracy: {accuracy}\")\n",
        "\n",
        "print(\"Best Model:\", best_model, final_scores[best_model])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFGfAnscNoRs",
        "outputId": "37202dab-7175-440b-b1e9-583406936077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.703125\n",
            "SVM Accuracy: 0.6375\n",
            "Logistic Regression Accuracy: 0.625\n",
            "Decision Tree Accuracy: 0.665625\n",
            "Best Model: Random Forest 0.703125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOMjG0sIarlB",
        "outputId": "6b9ed058-b647-4471-f17d-fa19bc29b7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-23.9.7-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.9.7 scikit-optimize-0.9.0\n",
            "SVM - Tuned Hyperparameters: OrderedDict([('C', 46915.05705722399), ('kernel', 'rbf')]), Accuracy: 0.635\n",
            "SVM - Tuned Hyperparameters: OrderedDict([('C', 1.9360537965638225), ('kernel', 'linear')]), Accuracy: 0.59\n",
            "SVM - Tuned Hyperparameters: OrderedDict([('C', 46915.05705722399), ('kernel', 'rbf')]), Accuracy: 0.66\n",
            "SVM - Tuned Hyperparameters: OrderedDict([('C', 46915.05705722399), ('kernel', 'rbf')]), Accuracy: 0.61\n",
            "SVM - Tuned Hyperparameters: OrderedDict([('C', 46915.05705722399), ('kernel', 'rbf')]), Accuracy: 0.6\n",
            "SVM - Tuned Hyperparameters: OrderedDict([('C', 46915.05705722399), ('kernel', 'rbf')]), Accuracy: 0.54\n",
            "SVM - Tuned Hyperparameters: OrderedDict([('C', 46915.05705722399), ('kernel', 'rbf')]), Accuracy: 0.595\n",
            "SVM - Tuned Hyperparameters: OrderedDict([('C', 46915.05705722399), ('kernel', 'rbf')]), Accuracy: 0.5829145728643216\n",
            "Random Forest - Tuned Hyperparameters: OrderedDict([('max_depth', 21), ('min_samples_leaf', 2), ('min_samples_split', 4), ('n_estimators', 46)]), Accuracy: 0.74\n",
            "Random Forest - Tuned Hyperparameters: OrderedDict([('max_depth', 21), ('min_samples_leaf', 2), ('min_samples_split', 4), ('n_estimators', 46)]), Accuracy: 0.71\n",
            "Random Forest - Tuned Hyperparameters: OrderedDict([('max_depth', 21), ('min_samples_leaf', 2), ('min_samples_split', 4), ('n_estimators', 46)]), Accuracy: 0.715\n",
            "Random Forest - Tuned Hyperparameters: OrderedDict([('max_depth', 21), ('min_samples_leaf', 2), ('min_samples_split', 4), ('n_estimators', 46)]), Accuracy: 0.7\n",
            "Random Forest - Tuned Hyperparameters: OrderedDict([('max_depth', 21), ('min_samples_leaf', 2), ('min_samples_split', 4), ('n_estimators', 46)]), Accuracy: 0.7\n",
            "Random Forest - Tuned Hyperparameters: OrderedDict([('max_depth', 21), ('min_samples_leaf', 2), ('min_samples_split', 4), ('n_estimators', 46)]), Accuracy: 0.595\n",
            "Random Forest - Tuned Hyperparameters: OrderedDict([('max_depth', 21), ('min_samples_leaf', 2), ('min_samples_split', 4), ('n_estimators', 46)]), Accuracy: 0.7\n",
            "Random Forest - Tuned Hyperparameters: OrderedDict([('max_depth', 21), ('min_samples_leaf', 2), ('min_samples_split', 4), ('n_estimators', 46)]), Accuracy: 0.7185929648241206\n",
            "Bayesian Optimization for Logistic Regression raised an exception: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "Decision Tree - Tuned Hyperparameters: OrderedDict([('max_depth', 53), ('min_samples_leaf', 1), ('min_samples_split', 6)]), Accuracy: 0.695\n",
            "Decision Tree - Tuned Hyperparameters: OrderedDict([('max_depth', 38), ('min_samples_leaf', 4), ('min_samples_split', 5)]), Accuracy: 0.605\n",
            "Decision Tree - Tuned Hyperparameters: OrderedDict([('max_depth', 53), ('min_samples_leaf', 1), ('min_samples_split', 6)]), Accuracy: 0.575\n",
            "Decision Tree - Tuned Hyperparameters: OrderedDict([('max_depth', 53), ('min_samples_leaf', 1), ('min_samples_split', 6)]), Accuracy: 0.62\n",
            "Decision Tree - Tuned Hyperparameters: OrderedDict([('max_depth', 53), ('min_samples_leaf', 1), ('min_samples_split', 6)]), Accuracy: 0.56\n",
            "Decision Tree - Tuned Hyperparameters: OrderedDict([('max_depth', 10), ('min_samples_leaf', 6), ('min_samples_split', 12)]), Accuracy: 0.615\n",
            "Decision Tree - Tuned Hyperparameters: OrderedDict([('max_depth', 10), ('min_samples_leaf', 6), ('min_samples_split', 12)]), Accuracy: 0.585\n",
            "Decision Tree - Tuned Hyperparameters: OrderedDict([('max_depth', 53), ('min_samples_leaf', 1), ('min_samples_split', 6)]), Accuracy: 0.6130653266331658\n",
            "SVM Outer CV Mean Accuracy: 0.6016143216080403\n",
            "Random Forest Outer CV Mean Accuracy: 0.6973241206030151\n",
            "Logistic Regression Outer CV Mean Accuracy: nan\n",
            "Decision Tree Outer CV Mean Accuracy: 0.6085081658291457\n",
            "Best Outer Model: Random Forest 0.6973241206030151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-8633489edd76>:84: RuntimeWarning: Mean of empty slice\n",
            "  mean_accuracy = np.nanmean(scores)  # Handling NaN values\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "data = pd.read_csv('wineq.csv')\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Outer loop for nested cross-validation\n",
        "outer_cv = 8\n",
        "inner_cv = 8\n",
        "outer_scores = {}\n",
        "\n",
        "# Algorithm Selection\n",
        "models = [\n",
        "    ('SVM', SVC()),\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('Logistic Regression', LogisticRegression()),\n",
        "    ('Decision Tree', DecisionTreeClassifier())\n",
        "]\n",
        "\n",
        "# Hyperparameter Optimization using Bayesian Optimization\n",
        "param_grids = {\n",
        "    'SVM': {\n",
        "         'C': Real(1e-5, 1e+5, prior='log-uniform'),\n",
        "        'kernel': Categorical(['linear', 'rbf', 'poly', 'sigmoid'])\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'n_estimators': Integer(10, 200),\n",
        "        'max_depth': Integer(10, 30),\n",
        "        'min_samples_split': Integer(1, 10),\n",
        "        'min_samples_leaf': Integer(1, 10)\n",
        "    },\n",
        "    'Logistic Regression': {\n",
        "        'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "        'penalty': Categorical(['l1', 'l2']),\n",
        "        'solver': Categorical(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'max_depth': Integer(1, 100),\n",
        "        'min_samples_split': Integer(2, 15),\n",
        "        'min_samples_leaf': Integer(1, 7)\n",
        "    }\n",
        "}\n",
        "\n",
        "for name, model in models:\n",
        "    try:\n",
        "        outer_scores[name] = []\n",
        "        for outer_train_index, outer_test_index in StratifiedKFold(n_splits=outer_cv, shuffle=True, random_state=0).split(X, y):\n",
        "            X_outer_train, X_outer_test = X[outer_train_index], X[outer_test_index]\n",
        "            y_outer_train, y_outer_test = y[outer_train_index], y[outer_test_index]\n",
        "\n",
        "            # Inner loop for hyperparameter tuning\n",
        "            opt = BayesSearchCV(\n",
        "                model,\n",
        "                param_grids[name],\n",
        "                n_iter=10,\n",
        "                cv=StratifiedKFold(n_splits=inner_cv, shuffle=True, random_state=0),\n",
        "                scoring='accuracy',\n",
        "                n_jobs=-1,\n",
        "                random_state=0\n",
        "            )\n",
        "            opt.fit(X_outer_train, y_outer_train)\n",
        "            best_model = opt.best_estimator_\n",
        "\n",
        "            # Evaluate on the outer test set\n",
        "            accuracy = best_model.score(X_outer_test, y_outer_test)\n",
        "            outer_scores[name].append(accuracy)\n",
        "\n",
        "            print(f\"{name} - Tuned Hyperparameters: {opt.best_params_}, Accuracy: {accuracy}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Bayesian Optimization for {name} raised an exception: {e}\")\n",
        "\n",
        "# Display results\n",
        "for name, scores in outer_scores.items():\n",
        "    mean_accuracy = np.nanmean(scores)  # Handling NaN values\n",
        "    print(f\"{name} Outer CV Mean Accuracy: {mean_accuracy}\")\n",
        "\n",
        "best_outer_model_name = max(outer_scores, key=outer_scores.get)\n",
        "print(\"Best Outer Model:\", best_outer_model_name, np.mean(outer_scores[best_outer_model_name]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import numpy as np\n",
        "\n",
        "model_results = [outer_scores[model_name] for model_name in outer_scores]\n",
        "\n",
        "flat_results = [score for scores in model_results for score in scores]\n",
        "\n",
        "\n",
        "labels = []\n",
        "for model_name, scores in outer_scores.items():\n",
        "    labels.extend([model_name] * len(scores))\n",
        "\n",
        "\n",
        "tukey_results = pairwise_tukeyhsd(np.array(flat_results), labels, alpha=0.05)\n",
        "from tabulate import tabulate\n",
        "tukey_df = pd.DataFrame(data=tukey_results._results_table.data[1:], columns=tukey_results._results_table.data[0])\n",
        "print(tabulate(tukey_df, headers='keys', tablefmt='pretty', showindex=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpLkxy-4J7Ya",
        "outputId": "220ce9bc-3ade-4f78-e177-d794ebf80a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---------------+----------+--------+---------+---------+--------+\n",
            "|    group1     |    group2     | meandiff | p-adj  |  lower  |  upper  | reject |\n",
            "+---------------+---------------+----------+--------+---------+---------+--------+\n",
            "| Decision Tree | Random Forest |  0.0888  | 0.0007 | 0.0382  | 0.1394  |  True  |\n",
            "| Decision Tree |      SVM      | -0.0069  | 0.9373 | -0.0575 | 0.0437  | False  |\n",
            "| Random Forest |      SVM      | -0.0957  | 0.0003 | -0.1463 | -0.0451 |  True  |\n",
            "+---------------+---------------+----------+--------+---------+---------+--------+\n"
          ]
        }
      ]
    }
  ]
}